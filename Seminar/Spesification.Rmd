---
title: "sem3_spesification.R"
author: "E"
date: "1/27/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Seminar 3 OLS, Spesification

### 1)

Model: $$\ y = E[y|x,z] + \epsilon $$

Choose preferred specification, and the object is to predict.

```{r, hide = F}

sem1ex1 <- haven::read_dta("data/econ4137sem1ex1.dta")

summary(sem1ex1)

# 1) linaer
sem1ex1 %>%  lm( y ~ x , data = .) %>% summary()

# log -log
sem1ex1 %>%  lm( log(y) ~ I( log(x)) + z , data = .) %>% summary()

# log-log
sem1ex1 %>%  lm( log(y) ~ I( log(x)) , data = .) %>% summary()

```

#### ii) Test functional form

With two alternative models that are non nested, the RÂ² and AIC/BIC cant be used. An alternativ approch is to use the Box-Cox transformation (PE-test).

*1) Estimate both models.*

*2) predict* $\hat{y}$ and $\hat{log(y)}$\*

\*3) t-statistics of $\delta$ and model $y = x\beta + \delta_{tLLM}[(log(y) - log(\hat{y})] + \epsilon$

```{r}

model_l <- sem1ex1 %>% lm( y ~x, data = .)
model_log <- sem1ex1 %>% lm( I(log(y)) ~I(log(x)), data = .)

# fit the model
sem1ex1$yhat <- model_l$fitted.values
sem1ex1$yhat_log <- model_log$fitted.values

PE_test <- sem1ex1 %>% 
  mutate( yhat_test = (log(yhat) - yhat_log),
          ) %>% 
  lm( y ~ x + yhat_test, data = .)

summary(PE_test)

```

PE_test - cant rejcet log model. Appear that linear model is preferred.

```{r}
PE_test2 <- sem1ex1 %>% 
  mutate( log_test = (yhat - exp(yhat_log) ) )%>% 
  lm( y ~ x + log_test, data = .)

summary(PE_test2)
```

cant reject. Seems that also log-model are preferred.

## 2 3.2 Verbeek

Clothing.dta contains information of sales, size and other characteristics of 400 Dutch men\`s fashion stores.

Goal is to explain sales per squaremetre (sales).

```{r}
fs::ls_dir()
clothing <- haven::read_dta("data/clothing.dta")

head(clothing)
```

#### a1)

The linear model D:

$$
log(sales) = x\beta + \epsilon  
$$

Where x = {log sales, log shop size and a constant}.

```{r}
mD <- clothing %>% mutate( lnsales = log(sales),
                           lnhourw = log(hoursw),
                           lnsize = log(ssize)
                           ) %>% 
  lm( lnsales ~ lnhourw + lnsize , data = .)

summary(mD)
```

#### a2) The linear model: $sales = \alpha + x\beta + hoursw + size$

```{r}

modelA <- clothing %>% lm( sales ~ hoursw + ssize, data = .)

summary(modelA)
```

#### b) RESET

```{r}
clothing$ma_fitted <- (modelA$fitted.values)^2

RESET_ma <- clothing %>% lm( sales ~ hourspw + ssize + ma_fitted, data = .)

summary(RESET_ma)

```

The RESET-test fail to reject \delta.

c)  Does number of owner affects shop sales?

```{r}
model_owner <- clothing %>% lm( sales ~ hoursw + ssize + nown, data = .)

summary(model_owner)

# F-test
f_statistic <- function(mR, mUnR){
  
  R2rest <- summary(mR)$r.squared 
  R2unr <- summary(mUnR)$r.squared
    
  ((R2unr-R2rest)/1)/( (1-R2unr)/(nrow(summary(mR$model))-5))  
  
}

# Low F-stat -> cant reject H0, owner has impact
f_statistic(mR = modelA, mUnR = model_owner)

model_part_time <- clothing %>% lm( sales ~ hoursw + ssize + npart, data = .)

# Low F-stat -> cant reject H0, owner has impact
f_statistic(mR = modelA, mUnR = model_part_time)

```

#### e) Model B:

#### sales \~ owner, full-times workers,parttime workers and shopsize.

```{r}

modelB <- clothing %>% lm( sales ~ nown + nfull + npart + ssize , data = .)


modelB %>% summary()


```

```{r}
summary(modelA)$adj.r.squared
summary(modelB)$adj.r.squared

# non-nested F-test
clothing$mA_fitted <- modelA$fitted.values
clothing$mB_fitted <- modelB$fitted.values

PE <- clothing %>%
  mutate( y_t = (sales - mB_fitted) ) %>% 
  lm( sales ~ hoursw + ssize + y_t , data = .)

PE2 <- clothing %>%
  mutate( y_t = (sales - mA_fitted) ) %>% 
  lm( sales ~ nown + nfull + npart + ssize + y_t , data = .)

summary(PE)
summary(PE2)
```

Both are rejected. Both model seem appropriate. Cant conclude.

### h) The J-test

The H0-hypothesis-test that $\delta$ = 0, in (test of model A): $$y=x\beta+\delta*z\gamma + u =  x\beta+\delta {\hat{y_{B}}} + u$$ Because \beta, \delta and \gamma cant be identified. The

```{r}
# Model A)
modelA

j_test_a <- clothing %>% lm( sales ~ hoursw + ssize + mB_fitted , data = .)
j_test_b <- clothing %>% lm( sales ~  nown + nfull  + npart + ssize + mA_fitted, data = .)
# t-value test, test model A  
coef(summary(j_test_a))[4,3]

# t-value test, test model B  
coef(summary(j_test_b))[6,3]

```

Cant reject model A or model B.

### 2a) Estimate the model:

$$log(sale_i)= \beta*hourw_i + log(shopsize)+ u$$ Which model (A) or (2A) do you prefer?

```{r}
model_2a <- clothing %>%mutate( log_sales = log(sales), log_ssize = log(ssize)) %>% 
  lm( log_sales ~ log_ssize + hoursw, data = .) 

summary(modelA)
summary(model_2a)
```

Testing the linear model:

```{r}
clothing$fitted_2A <- model_2a$fitted.values

 clothing%>%
  mutate( log_mA_fitted = log(mA_fitted),
          yhat2A = exp(fitted_2A),
          v_test_linear = (log_mA_fitted - fitted_2A),
          v_test_log = (mA_fitted - yhat2A)) %>%
  na.omit()  -> PE_data
 
PE_test_a_2A <-  PE_data %>% lm( sales ~ hoursw + ssize + v_test_linear, data = .)
PE_test_logmodel <-  PE_data %>% lm( I(log(sales)) ~ I(log(hoursw)) + I(log(ssize)) + v_test_log, data = .) 
# t = 3.2 the linear model may be prefered
summary(PE_test_a_2A)

# t = 2.29 -> seems the linear model may be prefered
summary(PE_test_logmodel)

```

## 2. The lalonde data

```{r}
lalode <- haven::read_dta("data/lalonde.dta")

lalode_1 <- lalode %>% filter( sample %in% c(4,5)) 
```

Data from National Supported Work Demonstration (NSW). Treatment (T= 1) was temporary employed, while non-experimented data is from CPS

```{r}
lalode_1 %>% skimr::skim()
```

```{r}
lalode_1 %>%
  select(-outcome) %>% 
  pivot_longer( names_to = "var", values_to = "values", age:earnings78) %>% 
  group_by( var) %>%
  mutate( dummie = ifelse( var %in% c("black", "hispanic", "married", "nodegree"), 1,0 )) %>% 
  filter( dummie == 0   ) %>% 
  mutate( values_2 = values/max(values, na.rm = T),
          big_value = ifelse( str_detect(var, "earnings|age"), "Big", "small  value")
          ) %>% 
  ggplot( aes( x = var, y = values, fill = factor(treatment) )) + geom_boxplot( )  +
  scale_y_log10() +
  coord_flip()
```

```{r}
ate1 <- lalode_1 %>% lm( earnings78 ~ treatment, data = .)

ate2 <- lalode_1 %>% lm( earnings78 ~ treatment + age + earnings75 + hispanic + black + married + education + nodegree, data = .)

ate1 %>% summary()
ate2 %>% summary()
```

Average treatment effect is 886 with no cotrols and 800 with controls. The result is based on a random assignment sample.

#### d) Using the CPS (non-random sample), and use the non-random sample as a control group.

```{r}
lalode_2 <- lalode %>% filter( sample %in% c(3,5))

viz_dta <- lalode_2 %>% 
    select(-outcome) %>% 
  pivot_longer( names_to = "var", values_to = "values", age:earnings78) %>% 
  group_by( var) %>%
  mutate( dummie = ifelse( var %in% c("black", "hispanic", "married", "nodegree"), 1,0 ))

viz_dta %>% filter( dummie == 0   ) %>% 
  mutate( values_2 = values/max(values, na.rm = T),
          big_value = ifelse( str_detect(var, "earnings|age"), "Big", "small  value")
          ) %>% 
  ggplot( aes( x = fct_reorder(var, values) , y = values, fill = factor(treatment) )) + geom_boxplot( )  +
  scale_y_log10() +
  coord_flip()

#
viz_dta %>% 
  filter( dummie == 1 ) %>% 
  group_by(  var, treatment) %>% 
  summarise( antall = n(), mean = mean(values), sd = sd(values) ) %>%
  ggplot( aes(y = mean, x = fct_reorder(var, mean), fill = factor(treatment), color = factor(treatment) )) +
  geom_col( position = position_dodge2()) +
  coord_flip()
  

```
